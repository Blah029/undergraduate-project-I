{"cells":[{"cell_type":"code","execution_count":37,"metadata":{"id":"Y_ZthfPvBcTM","executionInfo":{"status":"ok","timestamp":1688155882050,"user_tz":-330,"elapsed":573,"user":{"displayName":"WARNAKULASURIYA R.","userId":"17620947603870980673"}}},"outputs":[],"source":["import math\n","import numpy as np\n","import pickle\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","\n","## Import necessary items from Keras\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Activation, Dropout, UpSampling2D\n","from keras.layers import Conv2DTranspose, Conv2D, MaxPooling2D\n","from keras.layers import BatchNormalization\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import regularizers"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3653,"status":"ok","timestamp":1688155886451,"user":{"displayName":"WARNAKULASURIYA R.","userId":"17620947603870980673"},"user_tz":-330},"id":"-Uk_4fSZpmzZ","outputId":"7eca97e9-6cfd-402d-cf0c-6fbe2a602f10"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","working_dir = \"/content/gdrive/MyDrive/4th Year/7th Semester/EE405 Undergraduate Project I/G-08-2023/Shared Items\""]},{"cell_type":"code","execution_count":39,"metadata":{"id":"kt8oFvmCCIVs","executionInfo":{"status":"ok","timestamp":1688155886452,"user_tz":-330,"elapsed":5,"user":{"displayName":"WARNAKULASURIYA R.","userId":"17620947603870980673"}}},"outputs":[],"source":["def create_model(input_shape, pool_size):\n","    ## Create the actual neural network here\n","    model = Sequential()\n","\n","    ## Normalizes incoming inputs. First layer needs the input shape to work\n","    model.add(BatchNormalization(input_shape=input_shape))\n","\n","    ## Below layers were re-named for easier reading of model summary; this not necessary\n","    ## Conv Layer 1\n","    model.add(Conv2D(8, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv1'))\n","\n","    ## Conv Layer 2\n","    model.add(Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv2'))\n","\n","    ## Pooling 1\n","    model.add(MaxPooling2D(pool_size=pool_size))\n","\n","    ## Conv Layer 3\n","    model.add(Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv3'))\n","    model.add(Dropout(0.2))\n","\n","    ## Conv Layer 4\n","    model.add(Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv4'))\n","    model.add(Dropout(0.2))\n","\n","    ## Conv Layer 5\n","    model.add(Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv5'))\n","    model.add(Dropout(0.2))\n","\n","    ## Pooling 2\n","    model.add(MaxPooling2D(pool_size=pool_size))\n","\n","    ## Conv Layer 6\n","    model.add(Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv6'))\n","    model.add(Dropout(0.2))\n","\n","    ## Conv Layer 7\n","    model.add(Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv7'))\n","    model.add(Dropout(0.2))\n","\n","    ## Pooling 3\n","    model.add(MaxPooling2D(pool_size=pool_size))\n","\n","    ## Upsample 1\n","    model.add(UpSampling2D(size=pool_size))\n","\n","    ## Deconv 1\n","    model.add(Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv1'))\n","    model.add(Dropout(0.2))\n","\n","    ## Deconv 2\n","    model.add(Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv2'))\n","    model.add(Dropout(0.2))\n","\n","    ## Upsample 2\n","    model.add(UpSampling2D(size=pool_size))\n","\n","    ## Deconv 3\n","    model.add(Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv3'))\n","    model.add(Dropout(0.2))\n","\n","    ## Deconv 4\n","    model.add(Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv4'))\n","    model.add(Dropout(0.2))\n","\n","    ## Deconv 5\n","    model.add(Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv5'))\n","    model.add(Dropout(0.2))\n","\n","    ## Upsample 3\n","    model.add(UpSampling2D(size=pool_size))\n","\n","    ## Deconv 6\n","    model.add(Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv6'))\n","\n","    ## Final layer - only including one channel so 1 filter\n","    model.add(Conv2DTranspose(1, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Final'))\n","\n","    return model"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"heFQxhWzCQ3C","executionInfo":{"status":"ok","timestamp":1688156083933,"user_tz":-330,"elapsed":197485,"user":{"displayName":"WARNAKULASURIYA R.","userId":"17620947603870980673"}},"outputId":"f8f746ad-8c0f-4125-c3e4-5e8c8eb85167"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","2/2 [==============================] - 3s 433ms/step - loss: 0.1500 - val_loss: 0.1159\n","Epoch 2/150\n","2/2 [==============================] - 1s 407ms/step - loss: 0.1338 - val_loss: 0.1064\n","Epoch 3/150\n","2/2 [==============================] - 1s 564ms/step - loss: 0.1197 - val_loss: 0.1004\n","Epoch 4/150\n","2/2 [==============================] - 1s 402ms/step - loss: 0.1131 - val_loss: 0.0970\n","Epoch 5/150\n","2/2 [==============================] - 1s 620ms/step - loss: 0.1056 - val_loss: 0.0958\n","Epoch 6/150\n","2/2 [==============================] - 2s 626ms/step - loss: 0.1029 - val_loss: 0.0960\n","Epoch 7/150\n","2/2 [==============================] - 2s 640ms/step - loss: 0.1016 - val_loss: 0.0968\n","Epoch 8/150\n","2/2 [==============================] - 1s 419ms/step - loss: 0.1026 - val_loss: 0.0975\n","Epoch 9/150\n","2/2 [==============================] - 1s 578ms/step - loss: 0.1006 - val_loss: 0.0978\n","Epoch 10/150\n","2/2 [==============================] - 1s 407ms/step - loss: 0.1017 - val_loss: 0.0978\n","Epoch 11/150\n","2/2 [==============================] - 1s 556ms/step - loss: 0.1006 - val_loss: 0.0973\n","Epoch 12/150\n","2/2 [==============================] - 1s 537ms/step - loss: 0.1002 - val_loss: 0.0965\n","Epoch 13/150\n","2/2 [==============================] - 1s 545ms/step - loss: 0.0989 - val_loss: 0.0954\n","Epoch 14/150\n","2/2 [==============================] - 1s 403ms/step - loss: 0.0987 - val_loss: 0.0941\n","Epoch 15/150\n","2/2 [==============================] - 1s 553ms/step - loss: 0.0969 - val_loss: 0.0926\n","Epoch 16/150\n","2/2 [==============================] - 1s 402ms/step - loss: 0.0963 - val_loss: 0.0912\n","Epoch 17/150\n","2/2 [==============================] - 1s 640ms/step - loss: 0.0948 - val_loss: 0.0899\n","Epoch 18/150\n","2/2 [==============================] - 1s 719ms/step - loss: 0.0943 - val_loss: 0.0888\n","Epoch 19/150\n","2/2 [==============================] - 1s 395ms/step - loss: 0.0953 - val_loss: 0.0877\n","Epoch 20/150\n","2/2 [==============================] - 1s 555ms/step - loss: 0.0934 - val_loss: 0.0868\n","Epoch 21/150\n","2/2 [==============================] - 1s 555ms/step - loss: 0.0923 - val_loss: 0.0859\n","Epoch 22/150\n","2/2 [==============================] - 1s 561ms/step - loss: 0.0928 - val_loss: 0.0851\n","Epoch 23/150\n","2/2 [==============================] - 1s 566ms/step - loss: 0.0917 - val_loss: 0.0844\n","Epoch 24/150\n","2/2 [==============================] - 1s 528ms/step - loss: 0.0911 - val_loss: 0.0839\n","Epoch 25/150\n","2/2 [==============================] - 1s 577ms/step - loss: 0.0907 - val_loss: 0.0834\n","Epoch 26/150\n","2/2 [==============================] - 1s 571ms/step - loss: 0.0900 - val_loss: 0.0829\n","Epoch 27/150\n","2/2 [==============================] - 1s 822ms/step - loss: 0.0901 - val_loss: 0.0826\n","Epoch 28/150\n","2/2 [==============================] - 1s 656ms/step - loss: 0.0904 - val_loss: 0.0820\n","Epoch 29/150\n","2/2 [==============================] - 1s 579ms/step - loss: 0.0886 - val_loss: 0.0816\n","Epoch 30/150\n","2/2 [==============================] - 1s 415ms/step - loss: 0.0876 - val_loss: 0.0812\n","Epoch 31/150\n","2/2 [==============================] - 1s 399ms/step - loss: 0.0879 - val_loss: 0.0808\n","Epoch 32/150\n","2/2 [==============================] - 1s 390ms/step - loss: 0.0873 - val_loss: 0.0802\n","Epoch 33/150\n","2/2 [==============================] - 1s 416ms/step - loss: 0.0867 - val_loss: 0.0795\n","Epoch 34/150\n","2/2 [==============================] - 1s 587ms/step - loss: 0.0858 - val_loss: 0.0790\n","Epoch 35/150\n","2/2 [==============================] - 1s 547ms/step - loss: 0.0859 - val_loss: 0.0785\n","Epoch 36/150\n","2/2 [==============================] - 1s 548ms/step - loss: 0.0858 - val_loss: 0.0780\n","Epoch 37/150\n","2/2 [==============================] - 1s 398ms/step - loss: 0.0853 - val_loss: 0.0775\n","Epoch 38/150\n","2/2 [==============================] - 1s 627ms/step - loss: 0.0847 - val_loss: 0.0770\n","Epoch 39/150\n","2/2 [==============================] - 2s 846ms/step - loss: 0.0857 - val_loss: 0.0765\n","Epoch 40/150\n","2/2 [==============================] - 1s 398ms/step - loss: 0.0846 - val_loss: 0.0761\n","Epoch 41/150\n","2/2 [==============================] - 1s 556ms/step - loss: 0.0846 - val_loss: 0.0759\n","Epoch 42/150\n","2/2 [==============================] - 1s 413ms/step - loss: 0.0824 - val_loss: 0.0756\n","Epoch 43/150\n","2/2 [==============================] - 1s 575ms/step - loss: 0.0828 - val_loss: 0.0752\n","Epoch 44/150\n","2/2 [==============================] - 1s 402ms/step - loss: 0.0832 - val_loss: 0.0748\n","Epoch 45/150\n","2/2 [==============================] - 1s 395ms/step - loss: 0.0818 - val_loss: 0.0744\n","Epoch 46/150\n","2/2 [==============================] - 1s 414ms/step - loss: 0.0826 - val_loss: 0.0740\n","Epoch 47/150\n","2/2 [==============================] - 1s 551ms/step - loss: 0.0804 - val_loss: 0.0736\n","Epoch 48/150\n","2/2 [==============================] - 1s 393ms/step - loss: 0.0815 - val_loss: 0.0731\n","Epoch 49/150\n","2/2 [==============================] - 1s 882ms/step - loss: 0.0802 - val_loss: 0.0729\n","Epoch 50/150\n","2/2 [==============================] - 1s 713ms/step - loss: 0.0819 - val_loss: 0.0725\n","Epoch 51/150\n","2/2 [==============================] - 1s 417ms/step - loss: 0.0809 - val_loss: 0.0723\n","Epoch 52/150\n","2/2 [==============================] - 1s 570ms/step - loss: 0.0829 - val_loss: 0.0722\n","Epoch 53/150\n","2/2 [==============================] - 1s 559ms/step - loss: 0.0794 - val_loss: 0.0721\n","Epoch 54/150\n","2/2 [==============================] - 1s 399ms/step - loss: 0.0812 - val_loss: 0.0720\n","Epoch 55/150\n","2/2 [==============================] - 1s 406ms/step - loss: 0.0810 - val_loss: 0.0715\n","Epoch 56/150\n","2/2 [==============================] - 1s 542ms/step - loss: 0.0787 - val_loss: 0.0711\n","Epoch 57/150\n","2/2 [==============================] - 1s 409ms/step - loss: 0.0789 - val_loss: 0.0707\n","Epoch 58/150\n","2/2 [==============================] - 1s 542ms/step - loss: 0.0803 - val_loss: 0.0705\n","Epoch 59/150\n","2/2 [==============================] - 1s 396ms/step - loss: 0.0790 - val_loss: 0.0702\n","Epoch 60/150\n","2/2 [==============================] - 1s 623ms/step - loss: 0.0787 - val_loss: 0.0699\n","Epoch 61/150\n","2/2 [==============================] - 2s 657ms/step - loss: 0.0769 - val_loss: 0.0696\n","Epoch 62/150\n","2/2 [==============================] - 1s 403ms/step - loss: 0.0775 - val_loss: 0.0694\n","Epoch 63/150\n","2/2 [==============================] - 1s 406ms/step - loss: 0.0782 - val_loss: 0.0691\n","Epoch 64/150\n","2/2 [==============================] - 1s 574ms/step - loss: 0.0779 - val_loss: 0.0689\n","Epoch 65/150\n","2/2 [==============================] - 1s 545ms/step - loss: 0.0773 - val_loss: 0.0688\n","Epoch 66/150\n","2/2 [==============================] - 1s 389ms/step - loss: 0.0783 - val_loss: 0.0686\n","Epoch 67/150\n","2/2 [==============================] - 1s 541ms/step - loss: 0.0774 - val_loss: 0.0685\n","Epoch 68/150\n","2/2 [==============================] - 1s 395ms/step - loss: 0.0774 - val_loss: 0.0682\n","Epoch 69/150\n","2/2 [==============================] - 1s 557ms/step - loss: 0.0782 - val_loss: 0.0683\n","Epoch 70/150\n","2/2 [==============================] - 1s 594ms/step - loss: 0.0769 - val_loss: 0.0682\n","Epoch 71/150\n","2/2 [==============================] - 2s 879ms/step - loss: 0.0774 - val_loss: 0.0678\n","Epoch 72/150\n","2/2 [==============================] - 1s 619ms/step - loss: 0.0778 - val_loss: 0.0678\n","Epoch 73/150\n","2/2 [==============================] - 1s 570ms/step - loss: 0.0773 - val_loss: 0.0679\n","Epoch 74/150\n","2/2 [==============================] - 1s 402ms/step - loss: 0.0766 - val_loss: 0.0677\n","Epoch 75/150\n","2/2 [==============================] - 1s 550ms/step - loss: 0.0760 - val_loss: 0.0673\n","Epoch 76/150\n","2/2 [==============================] - 1s 567ms/step - loss: 0.0760 - val_loss: 0.0671\n","Epoch 77/150\n","2/2 [==============================] - 1s 396ms/step - loss: 0.0774 - val_loss: 0.0670\n","Epoch 78/150\n","2/2 [==============================] - 1s 400ms/step - loss: 0.0755 - val_loss: 0.0669\n","Epoch 79/150\n","2/2 [==============================] - 1s 552ms/step - loss: 0.0764 - val_loss: 0.0670\n","Epoch 80/150\n","2/2 [==============================] - 1s 536ms/step - loss: 0.0772 - val_loss: 0.0672\n","Epoch 81/150\n","2/2 [==============================] - 1s 834ms/step - loss: 0.0764 - val_loss: 0.0670\n","Epoch 82/150\n","2/2 [==============================] - 2s 847ms/step - loss: 0.0764 - val_loss: 0.0666\n","Epoch 83/150\n","2/2 [==============================] - 2s 840ms/step - loss: 0.0762 - val_loss: 0.0662\n","Epoch 84/150\n","2/2 [==============================] - 1s 416ms/step - loss: 0.0780 - val_loss: 0.0664\n","Epoch 85/150\n","2/2 [==============================] - 1s 420ms/step - loss: 0.0775 - val_loss: 0.0666\n","Epoch 86/150\n","2/2 [==============================] - 1s 541ms/step - loss: 0.0767 - val_loss: 0.0669\n","Epoch 87/150\n","2/2 [==============================] - 1s 544ms/step - loss: 0.0779 - val_loss: 0.0666\n","Epoch 88/150\n","2/2 [==============================] - 1s 536ms/step - loss: 0.0751 - val_loss: 0.0663\n","Epoch 89/150\n","2/2 [==============================] - 1s 395ms/step - loss: 0.0763 - val_loss: 0.0660\n","Epoch 90/150\n","2/2 [==============================] - 1s 527ms/step - loss: 0.0755 - val_loss: 0.0657\n","Epoch 91/150\n","2/2 [==============================] - 1s 409ms/step - loss: 0.0762 - val_loss: 0.0658\n","Epoch 92/150\n","2/2 [==============================] - 1s 427ms/step - loss: 0.0772 - val_loss: 0.0663\n","Epoch 93/150\n","2/2 [==============================] - 1s 835ms/step - loss: 0.0766 - val_loss: 0.0667\n","Epoch 94/150\n","2/2 [==============================] - 2s 644ms/step - loss: 0.0755 - val_loss: 0.0662\n","Epoch 95/150\n","2/2 [==============================] - 1s 550ms/step - loss: 0.0741 - val_loss: 0.0655\n","Epoch 96/150\n","2/2 [==============================] - 1s 569ms/step - loss: 0.0754 - val_loss: 0.0651\n","Epoch 97/150\n","2/2 [==============================] - 1s 556ms/step - loss: 0.0755 - val_loss: 0.0652\n","Epoch 98/150\n","2/2 [==============================] - 1s 527ms/step - loss: 0.0758 - val_loss: 0.0655\n","Epoch 99/150\n","2/2 [==============================] - 1s 575ms/step - loss: 0.0772 - val_loss: 0.0661\n","Epoch 100/150\n","2/2 [==============================] - 1s 467ms/step - loss: 0.0757 - val_loss: 0.0662\n","Epoch 101/150\n","2/2 [==============================] - 1s 551ms/step - loss: 0.0752 - val_loss: 0.0655\n","Epoch 102/150\n","2/2 [==============================] - 1s 738ms/step - loss: 0.0751 - val_loss: 0.0649\n","Epoch 103/150\n","2/2 [==============================] - 2s 656ms/step - loss: 0.0736 - val_loss: 0.0647\n","Epoch 104/150\n","2/2 [==============================] - 2s 852ms/step - loss: 0.0760 - val_loss: 0.0647\n","Epoch 105/150\n","2/2 [==============================] - 1s 561ms/step - loss: 0.0765 - val_loss: 0.0652\n","Epoch 106/150\n","2/2 [==============================] - 1s 551ms/step - loss: 0.0764 - val_loss: 0.0659\n","Epoch 107/150\n","2/2 [==============================] - 1s 411ms/step - loss: 0.0750 - val_loss: 0.0660\n","Epoch 108/150\n","2/2 [==============================] - 1s 558ms/step - loss: 0.0763 - val_loss: 0.0656\n","Epoch 109/150\n","2/2 [==============================] - 1s 572ms/step - loss: 0.0751 - val_loss: 0.0649\n","Epoch 110/150\n","2/2 [==============================] - 1s 413ms/step - loss: 0.0752 - val_loss: 0.0645\n","Epoch 111/150\n","2/2 [==============================] - 1s 395ms/step - loss: 0.0754 - val_loss: 0.0645\n","Epoch 112/150\n","2/2 [==============================] - 1s 411ms/step - loss: 0.0755 - val_loss: 0.0648\n","Epoch 113/150\n","2/2 [==============================] - 1s 405ms/step - loss: 0.0744 - val_loss: 0.0650\n","Epoch 114/150\n","2/2 [==============================] - 1s 622ms/step - loss: 0.0756 - val_loss: 0.0651\n","Epoch 115/150\n","2/2 [==============================] - 2s 845ms/step - loss: 0.0774 - val_loss: 0.0650\n","Epoch 116/150\n","2/2 [==============================] - 2s 897ms/step - loss: 0.0744 - val_loss: 0.0647\n","Epoch 117/150\n","2/2 [==============================] - 1s 575ms/step - loss: 0.0743 - val_loss: 0.0645\n","Epoch 118/150\n","2/2 [==============================] - 1s 402ms/step - loss: 0.0745 - val_loss: 0.0645\n","Epoch 119/150\n","2/2 [==============================] - 1s 408ms/step - loss: 0.0777 - val_loss: 0.0645\n","Epoch 120/150\n","2/2 [==============================] - 1s 425ms/step - loss: 0.0757 - val_loss: 0.0648\n","Epoch 121/150\n","2/2 [==============================] - 1s 565ms/step - loss: 0.0751 - val_loss: 0.0650\n","Epoch 122/150\n","2/2 [==============================] - 1s 421ms/step - loss: 0.0760 - val_loss: 0.0646\n","Epoch 123/150\n","2/2 [==============================] - 1s 416ms/step - loss: 0.0738 - val_loss: 0.0643\n","Epoch 124/150\n","2/2 [==============================] - 1s 394ms/step - loss: 0.0724 - val_loss: 0.0640\n","Epoch 125/150\n","2/2 [==============================] - 1s 818ms/step - loss: 0.0731 - val_loss: 0.0641\n","Epoch 126/150\n","2/2 [==============================] - 2s 703ms/step - loss: 0.0760 - val_loss: 0.0642\n","Epoch 127/150\n","2/2 [==============================] - 2s 983ms/step - loss: 0.0757 - val_loss: 0.0646\n","Epoch 128/150\n","2/2 [==============================] - 2s 701ms/step - loss: 0.0747 - val_loss: 0.0648\n","Epoch 129/150\n","2/2 [==============================] - 1s 558ms/step - loss: 0.0755 - val_loss: 0.0644\n","Epoch 130/150\n","2/2 [==============================] - 1s 413ms/step - loss: 0.0747 - val_loss: 0.0641\n","Epoch 131/150\n","2/2 [==============================] - 1s 577ms/step - loss: 0.0752 - val_loss: 0.0639\n","Epoch 132/150\n","2/2 [==============================] - 1s 416ms/step - loss: 0.0755 - val_loss: 0.0640\n","Epoch 133/150\n","2/2 [==============================] - 1s 558ms/step - loss: 0.0752 - val_loss: 0.0641\n","Epoch 134/150\n","2/2 [==============================] - 1s 581ms/step - loss: 0.0753 - val_loss: 0.0644\n","Epoch 135/150\n","2/2 [==============================] - 1s 639ms/step - loss: 0.0750 - val_loss: 0.0643\n","Epoch 136/150\n","2/2 [==============================] - 1s 640ms/step - loss: 0.0723 - val_loss: 0.0639\n","Epoch 137/150\n","2/2 [==============================] - 1s 434ms/step - loss: 0.0768 - val_loss: 0.0637\n","Epoch 138/150\n","2/2 [==============================] - 1s 633ms/step - loss: 0.0760 - val_loss: 0.0637\n","Epoch 139/150\n","2/2 [==============================] - 1s 566ms/step - loss: 0.0753 - val_loss: 0.0642\n","Epoch 140/150\n","2/2 [==============================] - 1s 420ms/step - loss: 0.0746 - val_loss: 0.0641\n","Epoch 141/150\n","2/2 [==============================] - 1s 439ms/step - loss: 0.0754 - val_loss: 0.0641\n","Epoch 142/150\n","2/2 [==============================] - 1s 602ms/step - loss: 0.0755 - val_loss: 0.0638\n","Epoch 143/150\n","2/2 [==============================] - 1s 592ms/step - loss: 0.0745 - val_loss: 0.0636\n","Epoch 144/150\n","2/2 [==============================] - 1s 429ms/step - loss: 0.0750 - val_loss: 0.0635\n","Epoch 145/150\n","2/2 [==============================] - 1s 675ms/step - loss: 0.0745 - val_loss: 0.0635\n","Epoch 146/150\n","2/2 [==============================] - 2s 892ms/step - loss: 0.0747 - val_loss: 0.0637\n","Epoch 147/150\n","2/2 [==============================] - 2s 903ms/step - loss: 0.0748 - val_loss: 0.0638\n","Epoch 148/150\n","2/2 [==============================] - 1s 596ms/step - loss: 0.0745 - val_loss: 0.0637\n","Epoch 149/150\n","2/2 [==============================] - 1s 551ms/step - loss: 0.0751 - val_loss: 0.0638\n","Epoch 150/150\n","2/2 [==============================] - 1s 425ms/step - loss: 0.0748 - val_loss: 0.0635\n"]}],"source":["def main():\n","    ## Load training images\n","    # train_images = pickle.load(open(f\"{working_dir}/Datasets/Pickle/full_CNN_train.p\", \"rb\" ))\n","    train_images = pickle.load(open(f\"{working_dir}/Datasets/Pickle/test_images_new_train.p\", \"rb\" ))\n","\n","    ## Load image labels\n","    # labels = pickle.load(open(f\"{working_dir}/Datasets/Pickle/full_CNN_labels.p\", \"rb\" ))\n","    labels = pickle.load(open(f\"{working_dir}/Datasets/Pickle/test_masks_new_train.p\", \"rb\" ))\n","\n","    ## Make into arrays as the neural network wants these\n","    train_images = np.array(train_images)\n","    labels = np.array(labels)\n","\n","    ## Try to fix TypeError: Cannot convert 0.11764705882352941 to EagerTensor of dtype int64\n","    # labels = labels.astype('float32')\n","\n","    ## Normalize labels - training images get normalized to start in the network\n","    labels = labels / 255\n","\n","    ## Shuffle images along with their labels, then split into training/validation sets\n","    train_images, labels = shuffle(train_images, labels)\n","    ## Test size may be 10% or 20%\n","    X_train, X_val, y_train, y_val = train_test_split(train_images, labels, test_size=0.1)\n","\n","    ## Batch size, epochs and pool size below are all paramaters to fiddle with for optimization\n","    batch_size = 128\n","    epochs = 150\n","    pool_size = (2, 2)\n","    input_shape = X_train.shape[1:]\n","\n","    ## Create the neural network\n","    # model = create_model(input_shape, pool_size)\n","    ## Load existing model\n","    model = keras.models.load_model(f\"{working_dir}/Models/full_CNN_model.h5\")\n","    ## Freeze layers\n","    for layer in model.layers[:-2]:\n","        layer.trainable = False\n","    # model.summary()\n","\n","    ## Using a generator to help the model use less data\n","    ## Channel shifts help with shadows slightly\n","    datagen = ImageDataGenerator(channel_shift_range=0.2)\n","    ## Augment dataset\n","    datagen = ImageDataGenerator(\n","        rotation_range=5,               # Rotate the image 5 degrees in each direction\n","        # width_shift_range=0.1,          # Skew the image\n","        # height_shift_range=0.1,         # Skew the image\n","        horizontal_flip=True,           # Mirror the image\n","        brightness_range=[0.8, 1.2],    # Slightly increase and decrease exposure\n","        channel_shift_range=0.2\n","    )\n","    datagen.fit(X_train)\n","\n","    ## Compiling and training the model\n","    model.compile(optimizer='Adam', loss='mean_squared_error')\n","    steps_per_epoch = math.ceil(len(X_train) / batch_size)\n","    model.fit(datagen.flow(X_train, y_train, batch_size=batch_size), steps_per_epoch=steps_per_epoch,\n","    epochs=epochs, verbose=1, validation_data=(X_val, y_val))\n","\n","    ## Freeze layers after training is done\n","    model.trainable = False\n","    model.compile(optimizer='Adam', loss='mean_squared_error')\n","\n","    ## Save model architecture and weights\n","    model.save('/content/gdrive/MyDrive/4th Year/7th Semester/EE405 Undergraduate Project I/G-08-2023/Shared Items/Models/test_model_new.h5')\n","\n","    ## Show summary of model\n","    # model.summary()\n","\n","if __name__ == '__main__':\n","    main()"]}],"metadata":{"colab":{"provenance":[{"file_id":"1Mbp0haBOzlg-RKVcN3MxDtYGZ0txCOn0","timestamp":1687251015854},{"file_id":"1HOvNW4bP2C3Ij3OImfTaEWt5UPaAn8Y5","timestamp":1686917874719}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}